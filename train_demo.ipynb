{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from utils.zsg_data import FlickrDataset\n",
    "# from models.slic_vit import SLICViT\n",
    "# from models.resnet_high_res import ResNetHighRes\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "# from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.vgp_data import FlickrVGPsDataset\n",
    "from models.vgp_vit import VGPViT\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreMapComparator(nn.Module):\n",
    "    def __init__(self, pretrained_model, pretrained_model_args):\n",
    "        super(ScoreMapComparator, self).__init__(pretrained_model)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 112 * 112, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.map_model = pretrained_model(**pretrained_model_args)\n",
    "\n",
    "    def forward(self, img, phrases):\n",
    "        x1,x2 = self.map_model(img, phrases)\n",
    "        x1 = self.pool(self.relu(self.conv1(x1)))\n",
    "        x2 = self.pool(self.relu(self.conv1(x2)))\n",
    "        x1 = x1.view(-1, 64 * 112 * 112)\n",
    "        x2 = x2.view(-1, 64 * 112 * 112)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gpu(gpu, args):\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.set_device(gpu)\n",
    "    rank = args.nr * args.gpus + gpu\t                          \n",
    "    dist.init_process_group(                                   \n",
    "    \tbackend='nccl',                                         \n",
    "   \t\tinit_method='env://',                                   \n",
    "    \tworld_size=args.world_size,                              \n",
    "    \trank=rank                                               \n",
    "    )      \n",
    "    return rank\n",
    "\n",
    "\n",
    "def load_dataset(rank, batch_size, args):\n",
    "    train_dataset = FlickrVGPsDataset(data_type='train')\n",
    "    val_dataset = FlickrVGPsDataset(data_type='val')\n",
    "    if args.num_samples > 0:\n",
    "        train_dataset.image_paths = train_dataset.image_paths[:args.num_samples]\n",
    "    # train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    # \ttrain_dataset,\n",
    "    # \tnum_replicas=args.world_size,\n",
    "    # \trank=rank\n",
    "    # )\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        # sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    # val_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    # \tval_dataset,\n",
    "    # \tnum_replicas=args.world_size,\n",
    "    # \trank=rank\n",
    "    # )\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        # sampler=val_sampler\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def setup_model(gpu, args):\n",
    "    # Score map model\n",
    "    if args.map_model == 'vgp_vit':\n",
    "        map_model = VGPViT\n",
    "        map_model_args = {\n",
    "            'model': 'vit14',\n",
    "            'alpha': 0.75,\n",
    "            'aggregation': 'mean',\n",
    "            'n_segments': list(range(100, 601, 50)),\n",
    "            'temperature': 0.02,\n",
    "            'upsample': 2,\n",
    "            'start_block': 0,\n",
    "            'compactness': 50,\n",
    "            'sigma': 0,\n",
    "        }\n",
    "    # TODO: other baseline models\n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "    # Train Similarity CNN\n",
    "    sim_net = ScoreMapComparator(map_model, map_model_args)\n",
    "    model = DDP(sim_net, device_ids=[gpu])\n",
    "\n",
    "\n",
    "def train(gpu, args):\n",
    "    rank = setup_gpu(gpu, args)\n",
    "    train_loader, val_loader = load_dataset(rank=rank,\n",
    "                                            batch_size=100, \n",
    "                                            args=args)\n",
    "    model = setup_model(gpu, args)\n",
    "\n",
    "    # Train\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    valid_loss = []\n",
    "    valid_acc = []\n",
    "\n",
    "    # 損失関数の定義\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 最適化手法の定義\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    start = datetime.now()\n",
    "    for epoch in range(args.epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "\n",
    "            for batch_idx, (idx, img, phrases, isVGPs) in tqdm(enumerate(dataloader)):\n",
    "                img, phrases = img.cuda(non_blocking=True), phrases.cuda(non_blocking=True)\n",
    "                isVGPs = isVGPs=='True'\n",
    "                isVGPs = isVGPs.cuda(non_blocking=True)\n",
    "                optimizer.zero_grad() # optimizerを初期化\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs = model(img, phrases)\n",
    "                    loss = criterion(outputs, isVGPs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "                    epoch_corrects += torch.sum(preds==isVGPs.data)\n",
    "        \n",
    "            epoch_loss = epoch_loss / len(dataloader.dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc.cpu())\n",
    "            else:\n",
    "                valid_loss.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc.cpu())\n",
    "\n",
    "            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "        # チェックポイントの保存\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict()\n",
    "                   },\n",
    "                   'checkpoints/checkpoint{}.pt'.format(epoch + 1))\n",
    "\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))\n",
    "        \n",
    "    return train_loss, train_acc, valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "args = {\n",
    "    'map_model': 'vgp_vit',\n",
    "    'task': 'train',\n",
    "    'num_samples': 80000,\n",
    "    'nodes': 1,\n",
    "    'gpus': 3,\n",
    "    'nr': 0,\n",
    "    'epochs': 100\n",
    "}\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict(args)\n",
    "args.world_size = args.gpus * args.nodes                #\n",
    "# os.environ['MASTER_ADDR'] = 'localhost'              #\n",
    "# os.environ['MASTER_PORT'] = '12345'                \n",
    "# mp.spawn(train, nprocs=args.gpus, args=(args,))  \n",
    "# rank = setup_gpu(gpu, args)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.set_device(gpu)\n",
    "train_loader, val_loader = load_dataset(rank=0,\n",
    "                                        batch_size=100, \n",
    "                                        args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[255, 190,   3],\n",
      "          [253, 184,   2],\n",
      "          [254, 181,   1],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[237, 172,  11],\n",
      "          [251, 185,  12],\n",
      "          [255, 191,  10],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[128,  31,   5],\n",
      "          [140,  48,   2],\n",
      "          [157,  72,   6],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  50,  19],\n",
      "          [ 80,  51,  19],\n",
      "          [ 79,  51,  20],\n",
      "          ...,\n",
      "          [ 84,  50,  20],\n",
      "          [ 82,  50,  18],\n",
      "          [ 80,  50,  16]],\n",
      "\n",
      "         [[ 71,  46,   8],\n",
      "          [ 72,  47,  10],\n",
      "          [ 75,  49,  11],\n",
      "          ...,\n",
      "          [ 83,  47,  20],\n",
      "          [ 84,  48,  22],\n",
      "          [ 83,  50,  19]],\n",
      "\n",
      "         [[ 79,  51,   9],\n",
      "          [ 75,  48,  12],\n",
      "          [ 74,  45,  10],\n",
      "          ...,\n",
      "          [ 78,  47,  14],\n",
      "          [ 79,  49,  18],\n",
      "          [ 77,  47,  14]]],\n",
      "\n",
      "\n",
      "        [[[226, 198, 181],\n",
      "          [227, 202, 187],\n",
      "          [226, 202, 193],\n",
      "          ...,\n",
      "          [ 52,  44,  38],\n",
      "          [ 61,  51,  40],\n",
      "          [ 61,  55,  52]],\n",
      "\n",
      "         [[227, 203, 188],\n",
      "          [224, 203, 194],\n",
      "          [226, 204, 197],\n",
      "          ...,\n",
      "          [ 73,  64,  52],\n",
      "          [ 74,  66,  55],\n",
      "          [ 77,  71,  62]],\n",
      "\n",
      "         [[229, 208, 197],\n",
      "          [231, 208, 195],\n",
      "          [229, 209, 201],\n",
      "          ...,\n",
      "          [ 89,  82,  67],\n",
      "          [ 96,  91,  79],\n",
      "          [104,  98,  83]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[236, 205, 174],\n",
      "          [233, 203, 185],\n",
      "          [236, 213, 188],\n",
      "          ...,\n",
      "          [249, 235, 224],\n",
      "          [246, 232, 217],\n",
      "          [238, 226, 207]],\n",
      "\n",
      "         [[250, 218, 185],\n",
      "          [252, 239, 213],\n",
      "          [253, 240, 223],\n",
      "          ...,\n",
      "          [241, 227, 211],\n",
      "          [237, 223, 212],\n",
      "          [232, 219, 204]],\n",
      "\n",
      "         [[251, 242, 231],\n",
      "          [253, 241, 235],\n",
      "          [252, 233, 209],\n",
      "          ...,\n",
      "          [234, 216, 180],\n",
      "          [228, 214, 204],\n",
      "          [225, 213, 209]]],\n",
      "\n",
      "\n",
      "        [[[ 21,  37,  14],\n",
      "          [ 20,  37,  15],\n",
      "          [ 19,  37,  16],\n",
      "          ...,\n",
      "          [ 24,  27,  16],\n",
      "          [ 17,  17,   8],\n",
      "          [ 26,  26,  16]],\n",
      "\n",
      "         [[ 21,  39,  14],\n",
      "          [ 22,  40,  15],\n",
      "          [ 23,  39,  16],\n",
      "          ...,\n",
      "          [ 21,  22,  13],\n",
      "          [ 27,  28,  16],\n",
      "          [ 28,  29,  16]],\n",
      "\n",
      "         [[ 23,  40,  14],\n",
      "          [ 25,  42,  16],\n",
      "          [ 24,  41,  16],\n",
      "          ...,\n",
      "          [ 28,  27,  20],\n",
      "          [ 23,  25,  16],\n",
      "          [ 20,  22,  14]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[151, 152, 146],\n",
      "          [153, 154, 149],\n",
      "          [157, 157, 151],\n",
      "          ...,\n",
      "          [163, 164, 159],\n",
      "          [160, 161, 155],\n",
      "          [158, 159, 152]],\n",
      "\n",
      "         [[154, 155, 148],\n",
      "          [151, 152, 146],\n",
      "          [156, 158, 152],\n",
      "          ...,\n",
      "          [158, 158, 153],\n",
      "          [163, 165, 159],\n",
      "          [157, 160, 153]],\n",
      "\n",
      "         [[150, 151, 145],\n",
      "          [155, 156, 151],\n",
      "          [149, 150, 144],\n",
      "          ...,\n",
      "          [161, 160, 155],\n",
      "          [156, 157, 151],\n",
      "          [145, 147, 141]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[155, 156, 151],\n",
      "          [156, 157, 152],\n",
      "          [150, 151, 146],\n",
      "          ...,\n",
      "          [ 97,  60,  55],\n",
      "          [ 93,  63,  59],\n",
      "          [ 93,  60,  56]],\n",
      "\n",
      "         [[151, 152, 147],\n",
      "          [153, 154, 149],\n",
      "          [156, 157, 152],\n",
      "          ...,\n",
      "          [ 74,  43,  41],\n",
      "          [ 82,  57,  55],\n",
      "          [ 93,  66,  64]],\n",
      "\n",
      "         [[154, 155, 150],\n",
      "          [151, 152, 147],\n",
      "          [154, 155, 150],\n",
      "          ...,\n",
      "          [ 74,  54,  55],\n",
      "          [ 88,  64,  59],\n",
      "          [ 97,  71,  65]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[202, 190, 178],\n",
      "          [190, 178, 175],\n",
      "          [191, 178, 177],\n",
      "          ...,\n",
      "          [177, 191, 218],\n",
      "          [187, 196, 220],\n",
      "          [194, 202, 224]],\n",
      "\n",
      "         [[191, 177, 172],\n",
      "          [190, 176, 170],\n",
      "          [196, 183, 178],\n",
      "          ...,\n",
      "          [ 53,  53,  94],\n",
      "          [ 61,  64, 113],\n",
      "          [ 72,  76, 126]],\n",
      "\n",
      "         [[205, 191, 180],\n",
      "          [193, 180, 173],\n",
      "          [197, 185, 182],\n",
      "          ...,\n",
      "          [105,  97,  73],\n",
      "          [ 80,  73,  63],\n",
      "          [ 76,  69,  62]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 85,   4,  11],\n",
      "          [121,  15,   9],\n",
      "          [163,  28,   4],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  1,   0,   0]],\n",
      "\n",
      "         [[ 92,   3,   9],\n",
      "          [128,  16,   9],\n",
      "          [165,  27,   3],\n",
      "          ...,\n",
      "          [  0,   0,   0],\n",
      "          [  1,   1,   1],\n",
      "          [  2,   0,   1]],\n",
      "\n",
      "         [[107,   9,  12],\n",
      "          [140,  20,   8],\n",
      "          [173,  30,   3],\n",
      "          ...,\n",
      "          [  2,   1,   1],\n",
      "          [  0,   0,   0],\n",
      "          [  2,   0,   1]]],\n",
      "\n",
      "\n",
      "        [[[ 45,  94, 161],\n",
      "          [ 25,  82, 143],\n",
      "          [ 11,  79, 137],\n",
      "          ...,\n",
      "          [  0,  61, 133],\n",
      "          [  0,  65, 141],\n",
      "          [  0,  64, 141]],\n",
      "\n",
      "         [[ 47, 102, 168],\n",
      "          [ 18,  87, 148],\n",
      "          [ 10,  83, 142],\n",
      "          ...,\n",
      "          [ 72, 135, 201],\n",
      "          [ 66, 133, 201],\n",
      "          [ 69, 135, 201]],\n",
      "\n",
      "         [[ 56, 105, 173],\n",
      "          [ 23,  83, 146],\n",
      "          [ 32,  87, 145],\n",
      "          ...,\n",
      "          [190, 189, 220],\n",
      "          [190, 190, 221],\n",
      "          [196, 195, 223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[116, 148, 225],\n",
      "          [118, 149, 220],\n",
      "          [116, 150, 216],\n",
      "          ...,\n",
      "          [103, 135,  58],\n",
      "          [ 89, 121,  43],\n",
      "          [103, 136,  53]],\n",
      "\n",
      "         [[102, 141, 232],\n",
      "          [106, 142, 230],\n",
      "          [107, 145, 231],\n",
      "          ...,\n",
      "          [120, 148,  59],\n",
      "          [121, 150,  68],\n",
      "          [111, 142,  55]],\n",
      "\n",
      "         [[ 97, 138, 231],\n",
      "          [ 99, 138, 230],\n",
      "          [ 97, 138, 232],\n",
      "          ...,\n",
      "          [124, 155,  61],\n",
      "          [107, 136,  38],\n",
      "          [114, 146,  56]]]], dtype=torch.uint8) <class 'torch.Tensor'> 100\n",
      "100\n",
      "[['a', 'white', 't-shirt'], ['two', 'elderly', 'women'], ['a', 'lightsaber'], ['a', 'sweatshirt'], ['a', 'table'], ['some', 'metal'], ['cap'], ['a', 'purple', 'outfit'], ['a', 'person'], ['a', 'man'], ['the', 'white', 'shirt'], ['a', 'cigarette'], ['a', 'kid'], ['a', 'blue', 'shirt'], ['a', 'woman'], ['her', 'cellphone'], ['a', 'large', ',', 'blue', 'duffel', 'bag'], ['blue', 'car'], ['a', 'red', 'sports', 'uniform'], ['a', 'graveled', 'path'], ['cup'], ['a', 'fence'], ['her', 'shirt'], ['a', 'teenage', 'boy'], ['a', 'patio', 'table'], ['rock', 'front'], ['a', 'group', 'of', 'onlookers'], ['spectacles'], ['glasses'], ['a', 'red', 'bike'], ['confetti'], ['a', 'smiling', 'blond', 'cheerleader'], ['food'], ['a', 'stool'], ['the', 'other'], ['one', 'person'], ['a', 'smiling', 'boy'], ['women'], ['the', 'number', '37'], ['glasses'], ['a', 'young', 'girl'], ['a', 'mountain'], ['a', 'pool', 'of', 'water'], ['a', 'number'], ['an', 'orange'], ['the', 'side', 'of', 'a', 'road'], ['trashcans'], ['sunglasses'], ['african', 'american', 'child'], ['bikinis'], ['a', 'paper'], ['a', 'young', 'woman'], ['a', 'man'], ['a', 'metal', 'disc'], ['a', 'blue', 'bathing', 'suit'], ['red', 'shirt', 'hike'], ['a', 'line'], ['blue', 'jackets'], ['his', 'hand'], ['some', 'tools'], ['the', 'sidewalk'], ['their', 'guitars'], ['a', 'green', 'striped', 'shirt'], ['old', 'man'], ['her', 'little', 'boy'], ['a', 'mask'], ['a', 'lake'], ['two', 'dogs'], ['little', 'girl'], ['a', 'black', 'dog'], ['a', 'can', 'of', 'beer'], ['a', 'couple', 'of', 'men'], ['boots'], ['a', 'group', 'of', 'children'], ['a', 'man'], ['two', 'women'], ['construction', 'equipment'], ['his', 'hand'], ['a', 'rider'], ['four', 'black', 'teenagers'], ['orange', 'vests'], ['a', 'young', 'girl'], ['a', 'banner'], ['a', 'middle-aged', 'man'], ['the', 'sidewalk'], ['jeans'], ['a', 'building'], ['a', 'woman'], ['a', 'piece', 'of', 'paper'], ['a', 'tennis', 'racket'], ['a', 'white', 'hat'], ['his', 'suit'], ['hat'], ['at', 'least', 'four', 'instrumentalists'], ['a', 'girl'], ['the', 'other'], ['a', 'lasso'], ['a', 'female', 'performer'], ['one', 'black', 'and', 'one', 'white'], ['a', 'frisbee']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'phrases_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c5b6850cde18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrases_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'phrases_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "for batch in tqdm(train_loader):\n",
    "    idices, images, phrase_pairs, labels = [d for d in batch.values()]\n",
    "    print(images, type(images), len(images))\n",
    "    print( len(phrase_pairs[0]))\n",
    "    images_tensor = [image.cuda(non_blocking=True) for image in images]\n",
    "    # print(images_tensor)\n",
    "    # Convert phrases list to a PyTorch tensor\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    tokenized_phrases = [[tokenizer(phrase) for phrase in phrase_list] for phrase_list in phrase_pairs]\n",
    "    print(tokenized_phrases[0])\n",
    "    # phrases_tensor = [[torch.tensor(tokenized_phrase) for tokenized_phrase in phrase_list] for phrase_list in tokenized_phrases]\n",
    "\n",
    "    labels = [label=='True' for label in labels]\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    labels_tensor = labels_tensor.cuda(non_blocking=True)\n",
    "\n",
    "\n",
    "    print(phrases_tensor)\n",
    "    print(labels_tensor)\n",
    "    print(len(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['his', 'teammates']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "print(tokenizer('his teammates'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
