import torch
import torch.nn as nn

class TextHeatmapCNN(nn.Module):
    """
    A Convolutional Network for Text + Heatmap similarity.

    A customized version of Siamese NN.
    """

    def __init__(self):
        super(TextHeatmapCNN, self).__init__()

        self.conv = nn.Sequential(
            nn.Conv2d(1, 64, 10, padding=1),  # 64@216*216
            nn.ReLU(inplace=True),
            nn.MaxPool2d(4, stride=2),  # 64@107*107
            nn.Conv2d(64, 128, 7, padding=3),
            nn.ReLU(inplace=True),  # 128@104*104
            nn.MaxPool2d(4, stride=4),  # 128@26*26
        )
        self.liner = nn.Sequential(nn.Linear(128*26*26, 4096), nn.Sigmoid())
        self.textliner = nn.Sequential(nn.Linear(768, 4096, dtype=torch.float16), nn.Sigmoid())
        self.out = nn.Linear(4096*2, 1)

        # weight init
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_uniform_(m.weight)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)

    def sub_forward(self, x):
        """
        Forward pass the input image through 1 subnetwork.

        Args
        ----
        - x: a Variable of size (B, C, H, W). Contains either the first or
          second image pair across the input batch.

        Returns
        -------
        - out: a Variable of size (B, 4096). The hidden vector representation
          of the input vector x.
        """
        x = self.conv(x)
        x = x.view(x.size()[0], -1)
        x = self.liner(x)
        return x
    def sub_text_forward(self, x):
        """
        Forward pass the input image through 1 subnetwork.

        Args
        ----
        - x: a Variable of size (B, C, N). Contains either the first or
          second text pair across the input batch.

        Returns
        -------
        - out: a Variable of size (B, 4096). The hidden vector representation
          of the input vector x.
        """
        x = self.textliner(x)
        return x

    def forward(self, x1, x2, t1, t2):
        """
        Forward pass the input image pairs through both subtwins. An image
        pair is composed of a left tensor x1 and a right tensor x2.

        Concretely, we compute the component-wise L1 distance of the hidden
        representations generated by each subnetwork, and feed the difference
        to a final fc-layer followed by a sigmoid activation function to
        generate a similarity score in the range [0, 1] for both embeddings.

        Args
        ----
        - x1: a Variable of size (B, C, H, W). The left image pairs along the
          batch dimension.
        - x2: a Variable of size (B, C, H, W). The right image pairs along the
          batch dimension.

        Returns
        -------
        - probas: a Variable of size (B, 1). A probability scalar indicating
          whether the left and right input pairs, along the batch dimension,
          correspond to the same class. We expect the network to spit out
          values near 1 when they belong to the same class, and 0 otherwise.
        """
        # encode image pairs
        h1 = self.sub_forward(x1)
        h2 = self.sub_forward(x2)

        # merge with text encode
        t1 = self.sub_text_forward(t1).squeeze(1)
        t2 = self.sub_text_forward(t2).squeeze(1)
        h1 = torch.cat((h1, t1), 1)
        h2 = torch.cat((h2, t2), 1)

        # compute l1 distance
        diff = torch.abs(h1 - h2)

        # score the similarity between the 2 encodings
        scores = self.out(diff)

        # return scores (without sigmoid) and use bce_with_logit
        # for increased numerical stability
        return scores