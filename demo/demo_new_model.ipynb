{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextHeatmapGatedClassifier(nn.Module):\n",
    "    def __init__(self, heatmap_only=False, text_only=False, use_dropout=False):\n",
    "        super(TextHeatmapGatedClassifier, self).__init__()\n",
    "        # \n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.heatmap_only = heatmap_only\n",
    "        self.text_only = text_only\n",
    "        self.batchnorm_visual = nn.BatchNorm1d(1000) # bn in visual fusion\n",
    "        self.batchnorm_text = nn.BatchNorm1d(1000) # bn in language fusion\n",
    "\n",
    "        # Map CNN\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 10, padding=1),  # 64@216*216\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),  # 64@108*108\n",
    "            nn.Conv2d(64, 128, 7),\n",
    "            nn.ReLU(inplace=True),  # 128@102*102\n",
    "            nn.MaxPool2d(2, stride=2),  # 128@51*51\n",
    "            \n",
    "            nn.Conv2d(128, 128, 4),\n",
    "            nn.ReLU(inplace=True),  # 128@48*48\n",
    "            nn.MaxPool2d(2, stride=2),  # 128@24*24\n",
    "        )\n",
    "\n",
    "        # Visual liners\n",
    "        self.visual_liner = nn.Sequential(\n",
    "            nn.Linear(128*24*24, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.visual_fuse = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.hidden_visual = nn.Sequential(\n",
    "            nn.Linear(1000, 300),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Text liners\n",
    "        self.text_liner = nn.Sequential(\n",
    "            nn.Linear(768, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.text_fuse = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.hidden_text = nn.Sequential(\n",
    "            nn.Linear(1000, 300),\n",
    "            nn.BatchNorm1d(300),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Gates\n",
    "        self.visual_gate = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000,300),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.text_gate = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000,300),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # output\n",
    "        self.logits = nn.Sequential(\n",
    "            nn.Linear(300, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # weight init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def visual_forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.visual_liner(x)\n",
    "        return x\n",
    "\n",
    "    def visual_fusion(self, v1, v2):\n",
    "        v = torch.cat((v1, v2), 1)\n",
    "        v = self.visual_fuse(v)\n",
    "        return v\n",
    "    \n",
    "    def text_forward(self, t):\n",
    "        t = self.text_liner(t)\n",
    "        return t\n",
    "    \n",
    "    def text_fusion(self, t1, t2):\n",
    "        t = torch.cat((t1, t2), 1)\n",
    "        t = self.text_fuse(t)\n",
    "        return t\n",
    "\n",
    "    def gate_calc(self, v, t):\n",
    "        x = torch.cat((v,t), 1)\n",
    "        g_v = self.visual_gate(x)\n",
    "        g_t = self.text_gate(x)\n",
    "        return g_v, g_t\n",
    "\n",
    "    def forward(self, x1, x2, t1, t2):\n",
    "        # merge text feature pairs\n",
    "        t1 = self.text_forward(t1)\n",
    "        t2 = self.text_forward(t2)\n",
    "        t = self.text_fusion(t1, t2)\n",
    "        h_t = self.hidden_text(t)\n",
    "        if self.text_only:\n",
    "            logits = self.logits(h_t)\n",
    "            return logits\n",
    "        \n",
    "        # encode image pairs\n",
    "        v1 = self.visual_forward(x1)\n",
    "        v2 = self.visual_forward(x2)\n",
    "        # fuse visual feature pairs\n",
    "        v = self.visual_fusion(v1, v2)\n",
    "        h_v = self.hidden_visual(v)\n",
    "        # Map only\n",
    "        if self.heatmap_only:\n",
    "            logits = self.logits(h_v)\n",
    "            return logits\n",
    "        \n",
    "        # fuse visual and text with gates\n",
    "        visual_gate, text_gate = self.gate_calc(v,t)\n",
    "        y = visual_gate*h_v + text_gate*h_t\n",
    "\n",
    "        logits = self.logits(y)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/adapting-CLIP-VGPs\n"
     ]
    }
   ],
   "source": [
    "%cd /work/adapting-CLIP-VGPs/\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.heatmap_data import VGPsHeatmapsDataset\n",
    "\n",
    "GPU = 4\n",
    "\n",
    "train_dataset = VGPsHeatmapsDataset(split='train')\n",
    "train_dataset.image_idices = train_dataset.image_idices[:100000]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    "    # sampler=train_sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextHeatmapGatedClassifier(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (batchnorm_visual): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_text): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (visual_liner): Sequential(\n",
       "    (0): Linear(in_features=73728, out_features=4096, bias=True)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (visual_fuse): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (hidden_visual): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "  )\n",
       "  (text_liner): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=4096, bias=True)\n",
       "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (text_fuse): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (hidden_text): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "  )\n",
       "  (visual_gate): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (text_gate): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (logits): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextHeatmapGatedClassifier().to(GPU)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数の定義: pair wise loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CosineEmbeddingLoss()\n",
    "# pairwise loss, contrastive los\n",
    "\n",
    "# 最適化手法の定義\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = GPU\n",
    "phase = 'train'\n",
    "\n",
    "batch_iter = iter(train_loader)\n",
    "batch = next(batch_iter)\n",
    "image_paths = batch['img_idx']\n",
    "left_text_ft = batch['left_text_emb']\n",
    "right_text_ft = batch['right_text_emb']\n",
    "left_heatmaps = batch['left_heatmap']\n",
    "right_heatmaps = batch['right_heatmap']\n",
    "labels = batch['label']\n",
    "\n",
    "left_heatmaps = left_heatmaps.unsqueeze(1).to(gpu)\n",
    "right_heatmaps = right_heatmaps.unsqueeze(1).to(gpu)\n",
    "left_text_ft = left_text_ft.squeeze(1).float().to(gpu)\n",
    "right_text_ft = right_text_ft.squeeze(1).float().to(gpu)\n",
    "label_tensor = labels.float().unsqueeze(1).to(gpu)\n",
    "\n",
    "epoch_loss = 0.0\n",
    "epoch_TP = 0\n",
    "epoch_FP = 0\n",
    "epoch_FN = 0\n",
    "epoch_TN = 0\n",
    "processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "with torch.set_grad_enabled(phase=='train'):\n",
    "    logits = model(left_heatmaps, right_heatmaps, left_text_ft, right_text_ft)\n",
    "    loss = criterion(logits, label_tensor)\n",
    "    epoch_loss += loss.item() * len(image_paths)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5050],\n",
       "        [0.7447],\n",
       "        [0.3901],\n",
       "        [0.6819],\n",
       "        [0.7844],\n",
       "        [0.8535],\n",
       "        [0.5290],\n",
       "        [0.5518],\n",
       "        [0.6048],\n",
       "        [0.4380],\n",
       "        [0.6518],\n",
       "        [0.7480],\n",
       "        [0.5290],\n",
       "        [0.6048],\n",
       "        [0.6518],\n",
       "        [0.7438],\n",
       "        [0.5165],\n",
       "        [0.7763],\n",
       "        [0.5064],\n",
       "        [0.5403],\n",
       "        [0.2950],\n",
       "        [0.4063],\n",
       "        [0.5064],\n",
       "        [0.2950],\n",
       "        [0.7507],\n",
       "        [0.3790],\n",
       "        [0.7400],\n",
       "        [0.7680],\n",
       "        [0.7864],\n",
       "        [0.7680],\n",
       "        [0.5914],\n",
       "        [0.8248],\n",
       "        [0.7042],\n",
       "        [0.6505],\n",
       "        [0.8614],\n",
       "        [0.8878],\n",
       "        [0.9425],\n",
       "        [0.7544],\n",
       "        [0.7235],\n",
       "        [0.7025],\n",
       "        [0.9151],\n",
       "        [0.9374],\n",
       "        [0.8788],\n",
       "        [0.8541],\n",
       "        [0.8936],\n",
       "        [0.8551],\n",
       "        [0.8268],\n",
       "        [0.8605],\n",
       "        [0.9533],\n",
       "        [0.7799],\n",
       "        [0.4781],\n",
       "        [0.6868],\n",
       "        [0.7415],\n",
       "        [0.4876],\n",
       "        [0.3816],\n",
       "        [0.4820],\n",
       "        [0.7004],\n",
       "        [0.8186],\n",
       "        [0.6471],\n",
       "        [0.3760],\n",
       "        [0.4305],\n",
       "        [0.3001],\n",
       "        [0.4569],\n",
       "        [0.8798],\n",
       "        [0.7798],\n",
       "        [0.4695],\n",
       "        [0.6439],\n",
       "        [0.4460],\n",
       "        [0.7193],\n",
       "        [0.5240],\n",
       "        [0.6478],\n",
       "        [0.7168],\n",
       "        [0.6346],\n",
       "        [0.9004],\n",
       "        [0.6209],\n",
       "        [0.8876],\n",
       "        [0.7548],\n",
       "        [0.9173],\n",
       "        [0.6448],\n",
       "        [0.8522],\n",
       "        [0.6633],\n",
       "        [0.8339],\n",
       "        [0.7812],\n",
       "        [0.4470],\n",
       "        [0.5409],\n",
       "        [0.8430],\n",
       "        [0.7927],\n",
       "        [0.7386],\n",
       "        [0.5538],\n",
       "        [0.6934],\n",
       "        [0.5541],\n",
       "        [0.7387],\n",
       "        [0.6154],\n",
       "        [0.7567],\n",
       "        [0.7610],\n",
       "        [0.5535],\n",
       "        [0.5849],\n",
       "        [0.7304],\n",
       "        [0.5598],\n",
       "        [0.6908]], device='cuda:4', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (logits>0.5).float()\n",
    "\n",
    "epoch_TP += ((preds.squeeze(1) == 1) & (label_tensor.squeeze(1) == 1)).float().sum().item()\n",
    "epoch_FP += ((preds.squeeze(1) == 1) & (label_tensor.squeeze(1) == 0)).float().sum().item()\n",
    "epoch_FN += ((preds.squeeze(1) == 0) & (label_tensor.squeeze(1) == 1)).float().sum().item()\n",
    "epoch_TN += ((preds.squeeze(1) == 0) & (label_tensor.squeeze(1) == 0)).float().sum().item()  \n",
    "epoch_prec = epoch_TP / (epoch_TP + epoch_FP) if (epoch_TP + epoch_FP) > 0 else 0\n",
    "epoch_rec = epoch_TP / (epoch_TP + epoch_FN) if (epoch_TP + epoch_FN) > 0 else 0\n",
    "epoch_f1 = 2 * epoch_prec * epoch_rec / (epoch_prec + epoch_rec) if (epoch_prec + epoch_rec) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1686746987951807"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30], device='cuda:4')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds==label_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
