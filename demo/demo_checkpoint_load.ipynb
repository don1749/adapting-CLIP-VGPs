{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint_path = '/work/adapting-CLIP-VGPs/checkpoints/text only/best model/checkpoint22.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'momentum_buffer': tensor([[ 8.1062e-06,  2.6989e-04,  4.2200e-05,  ..., -2.2531e-05,\n",
       "             2.7823e-04, -1.6165e-04],\n",
       "           [-1.4830e-04, -3.9101e-04,  9.2888e-04,  ..., -1.3041e-04,\n",
       "            -1.3328e-04,  5.8842e-04],\n",
       "           [ 5.8365e-04,  6.1035e-04,  1.1826e-04,  ...,  4.8339e-05,\n",
       "            -2.3425e-04, -1.1438e-04],\n",
       "           ...,\n",
       "           [ 8.4639e-05,  1.2875e-05, -3.1233e-04,  ...,  6.5947e-04,\n",
       "            -6.2644e-05,  1.1158e-04],\n",
       "           [ 1.1104e-04,  3.7253e-05,  2.7061e-05,  ...,  3.0696e-05,\n",
       "            -1.0061e-04, -1.0788e-05],\n",
       "           [ 4.0948e-05,  3.2258e-04,  3.5691e-04,  ..., -5.9319e-04,\n",
       "             2.4509e-04, -5.6124e-04]], dtype=torch.float16)},\n",
       "  1: {'momentum_buffer': tensor([ 2.4974e-05,  1.2517e-05,  2.1756e-05,  ..., -7.2479e-05,\n",
       "           -1.3709e-06,  7.2956e-05], dtype=torch.float16)},\n",
       "  2: {'momentum_buffer': tensor([[ 0.0006,  0.0009, -0.0006,  ...,  0.0018,  0.0008,  0.0021]],\n",
       "          dtype=torch.float16)},\n",
       "  3: {'momentum_buffer': tensor([0.0076], dtype=torch.float16)}},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'momentum': 0.9,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [0, 1, 2, 3]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['optimizer_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.text_heatmap_sigmoid import TextHeatmapSigmoidClassifier\n",
    "from collections import OrderedDict\n",
    "# # Adjust for 'DataParallel' consistency\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['model_state_dict'].items():\n",
    "    prefix = 'module.'\n",
    "    name = k[len(prefix):]  # remove `module.` prefix\n",
    "    new_state_dict[name] = v\n",
    "# model = TextHeatmapSigmoidClassifier(heatmap_only=True)\n",
    "# model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_liner.0.weight torch.Size([4096, 768])\n",
      "text_liner.0.bias torch.Size([4096])\n",
      "visual_liner.0.weight torch.Size([16384, 50176])\n",
      "visual_liner.0.bias torch.Size([16384])\n",
      "visual_liner.1.weight torch.Size([16384])\n",
      "visual_liner.1.bias torch.Size([16384])\n",
      "visual_liner.1.running_mean torch.Size([16384])\n",
      "visual_liner.1.running_var torch.Size([16384])\n",
      "visual_liner.1.num_batches_tracked torch.Size([])\n",
      "visual_liner.3.weight torch.Size([4096, 16384])\n",
      "visual_liner.3.bias torch.Size([4096])\n",
      "singlemodal_logits.0.weight torch.Size([1, 4096])\n",
      "singlemodal_logits.0.bias torch.Size([1])\n",
      "visual_reduce.weight torch.Size([1000, 4096])\n",
      "visual_reduce.bias torch.Size([1000])\n",
      "text_reduce.weight torch.Size([1000, 4096])\n",
      "text_reduce.bias torch.Size([1000])\n",
      "visual_gate.0.weight torch.Size([300, 1000])\n",
      "visual_gate.0.bias torch.Size([300])\n",
      "text_gate.0.weight torch.Size([300, 1000])\n",
      "text_gate.0.bias torch.Size([300])\n",
      "hidden_visual.weight torch.Size([300, 1000])\n",
      "hidden_visual.bias torch.Size([300])\n",
      "hidden_text.weight torch.Size([300, 1000])\n",
      "hidden_text.bias torch.Size([300])\n",
      "multimodal_logits.0.weight torch.Size([128, 300])\n",
      "multimodal_logits.0.bias torch.Size([128])\n",
      "multimodal_logits.1.weight torch.Size([128])\n",
      "multimodal_logits.1.bias torch.Size([128])\n",
      "multimodal_logits.1.running_mean torch.Size([128])\n",
      "multimodal_logits.1.running_var torch.Size([128])\n",
      "multimodal_logits.1.num_batches_tracked torch.Size([])\n",
      "multimodal_logits.3.weight torch.Size([1, 128])\n",
      "multimodal_logits.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for key, val in new_state_dict.items():\n",
    "    print(key, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OrderedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8bf77fbadd56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'module.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# remove `module.` prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnew_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OrderedDict' is not defined"
     ]
    }
   ],
   "source": [
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['model_state_dict'].items():\n",
    "    prefix = 'module.'\n",
    "    name = k[len(prefix):]  # remove `module.` prefix\n",
    "    new_state_dict[name] = v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
