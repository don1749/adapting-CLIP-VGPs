{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextHeatmapFinal(nn.Module):\n",
    "    '''\n",
    "    Combine best text classifer with most effective map fusion\n",
    "    '''\n",
    "    def __init__(self, heatmap_only=False, text_only=False):\n",
    "        super(TextHeatmapFinal, self).__init__()\n",
    "        # Modal setting\n",
    "        self.heatmap_only = heatmap_only\n",
    "        self.text_only = text_only\n",
    "\n",
    "        # Text Transform\n",
    "        self.text_liner = nn.Sequential(\n",
    "            nn.Linear(768, 4096),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.text_fusion_liner = nn.Sequential(\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.hidden_text = nn.Sequential(\n",
    "            nn.Linear(1000, 300),\n",
    "            nn.BatchNorm1d(300),\n",
    "        )\n",
    "\n",
    "        self.text_logits = nn.Sequential(\n",
    "            nn.Linear(4096, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Map CNN\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 10, padding=1),  # 8@216*216\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4, stride=4),  # 8@54*54\n",
    "            nn.Conv2d(8, 16, 7),\n",
    "            nn.ReLU(inplace=True),  # 8@48*48\n",
    "            nn.MaxPool2d(4, stride=4),  # 16@12*12\n",
    "        )\n",
    "\n",
    "        # Visual liners\n",
    "        self.visual_liner = nn.Sequential(\n",
    "            nn.Linear(16*12*12, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.visual_fusion_liner = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.hidden_visual = nn.Sequential(\n",
    "            nn.Linear(1000, 300),\n",
    "            nn.BatchNorm1d(300),\n",
    "        )\n",
    "\n",
    "        self.map_logits = nn.Sequential(\n",
    "            nn.Linear(300, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Gates\n",
    "        self.visual_gate = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000,300),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.text_gate = nn.Sequential(\n",
    "            nn.Linear(1000*2, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1000,300),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.multimodal_logits = nn.Sequential(\n",
    "            nn.Linear(300, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # weight init\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def visual_forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.visual_liner(x)\n",
    "        return x\n",
    "\n",
    "    def visual_fuse(self, x1, x2):\n",
    "        x1 = x1.view(x1.size()[0], -1)\n",
    "        x1 = self.visual_liner(x1)\n",
    "\n",
    "        x2 = x2.view(x2.size()[0], -1)\n",
    "        x2 = self.visual_liner(x2)\n",
    "        # Fuse\n",
    "        x = torch.abs(x1-x2)\n",
    "        return x\n",
    "    \n",
    "    def gate_calc(self, v, t):\n",
    "        x = torch.cat((v,t), 1)\n",
    "        g_v = self.visual_gate(x)\n",
    "        g_t = self.text_gate(x)\n",
    "        return g_v, g_t\n",
    "    \n",
    "    def forward(self, v1, v2, t1, t2):\n",
    "        # Text\n",
    "        t1 = self.text_liner(t1) # 768->4096\n",
    "        t2 = self.text_liner(t2) # 768->4096\n",
    "        t = torch.abs(t1-t2)\n",
    "        if self.text_only:\n",
    "            logits = self.text_logits(t) # 4906->1, sigmoid\n",
    "            return logits\n",
    "        t = self.text_fusion_liner(t) # 4096 -> 1000\n",
    "        h_t = self.hidden_text(t) # 1000->300\n",
    "        \n",
    "        # Map\n",
    "        v1 = self.visual_forward(v1) # 224*224->CNN->1000\n",
    "        v2 = self.visual_forward(v2) # 224*224->CNN->1000\n",
    "        v = torch.cat((v1, v2), 1) \n",
    "        v = self.visual_fusion_liner(v) # 2000->1000\n",
    "        h_v = self.hidden_visual(v)\n",
    "        if self.heatmap_only:\n",
    "            logits = self.map_logits(v)\n",
    "            return logits\n",
    "    \n",
    "        # Fusion\n",
    "        g_v, g_t = self.gate_calc(v,t)\n",
    "        tanh = nn.Tanh()\n",
    "        y = g_v*tanh(h_v) + g_t*tanh(h_t)\n",
    "        logits = self.multimodal_logits(y)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/adapting-CLIP-VGPs\n"
     ]
    }
   ],
   "source": [
    "%cd /work/adapting-CLIP-VGPs/\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.heatmap_data import VGPsHeatmapsDataset\n",
    "\n",
    "GPU = 0\n",
    "\n",
    "train_dataset = VGPsHeatmapsDataset(split='train')\n",
    "train_dataset.image_idices = train_dataset.image_idices[:200]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    "    # sampler=train_sampler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextHeatmapFinal(\n",
       "  (text_liner): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (text_fusion_liner): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (hidden_text): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (text_logits): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(10, 10), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (visual_liner): Sequential(\n",
       "    (0): Linear(in_features=2304, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (visual_fusion_liner): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (hidden_visual): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (map_logits): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (visual_gate): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (text_gate): Sequential(\n",
       "    (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=1000, out_features=300, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (multimodal_logits): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextHeatmapFinal().to(GPU)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数の定義: pair wise loss\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6.5]).to(GPU))\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# pairwise loss, contrastive los\n",
    "\n",
    "# 最適化手法の定義\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = GPU\n",
    "phase = 'train'\n",
    "\n",
    "batch_iter = iter(train_loader)\n",
    "batch = next(batch_iter)\n",
    "image_paths = batch['img_idx']\n",
    "left_text_ft = batch['left_text_emb']\n",
    "right_text_ft = batch['right_text_emb']\n",
    "left_heatmaps = batch['left_heatmap']\n",
    "right_heatmaps = batch['right_heatmap']\n",
    "labels = batch['label']\n",
    "\n",
    "left_heatmaps = left_heatmaps.unsqueeze(1).to(gpu)\n",
    "right_heatmaps = right_heatmaps.unsqueeze(1).to(gpu)\n",
    "left_text_ft = left_text_ft.squeeze(1).float().to(gpu)\n",
    "right_text_ft = right_text_ft.squeeze(1).float().to(gpu)\n",
    "label_tensor = labels.float().unsqueeze(1).to(gpu)\n",
    "\n",
    "epoch_loss = 0.0\n",
    "epoch_TP = 0\n",
    "epoch_FP = 0\n",
    "epoch_FN = 0\n",
    "epoch_TN = 0\n",
    "processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1593,  0.5981, -0.1082,  ..., -0.2119,  0.1201, -0.5293],\n",
       "        [ 0.1593,  0.5981, -0.1082,  ..., -0.2119,  0.1201, -0.5293],\n",
       "        [ 0.4602, -0.6152,  0.4688,  ...,  0.0058, -0.0092,  0.4028],\n",
       "        ...,\n",
       "        [ 0.1316,  0.7441,  0.2695,  ..., -0.4397, -0.0232,  0.3755],\n",
       "        [ 0.1316,  0.7441,  0.2695,  ..., -0.4397, -0.0232,  0.3755],\n",
       "        [ 0.0035,  0.2289,  0.4023,  ..., -0.0433,  0.1329, -0.6191]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_text_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "with torch.set_grad_enabled(phase=='train'):\n",
    "    logits = model(left_heatmaps, right_heatmaps, left_text_ft, right_text_ft)\n",
    "    loss = criterion(logits, label_tensor)\n",
    "    preds = (logits>0.5).float()\n",
    "    # loss = criterion(logits, torch.squeeze(label_tensor.type(torch.long)))\n",
    "    # _, preds = logits.max(dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_TP += ((preds.squeeze(1) == 1) & (label_tensor.squeeze(1) == 1)).float().sum().item()\n",
    "epoch_FP += ((preds.squeeze(1) == 1) & (label_tensor.squeeze(1) == 0)).float().sum().item()\n",
    "epoch_FN += ((preds.squeeze(1) == 0) & (label_tensor.squeeze(1) == 1)).float().sum().item()\n",
    "epoch_TN += ((preds.squeeze(1) == 0) & (label_tensor.squeeze(1) == 0)).float().sum().item()  \n",
    "epoch_prec = epoch_TP / (epoch_TP + epoch_FP) if (epoch_TP + epoch_FP) > 0 else 0\n",
    "epoch_rec = epoch_TP / (epoch_TP + epoch_FN) if (epoch_TP + epoch_FN) > 0 else 0\n",
    "epoch_f1 = 2 * epoch_prec * epoch_rec / (epoch_prec + epoch_rec) if (epoch_prec + epoch_rec) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13725490196078433"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21212121212121213"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
